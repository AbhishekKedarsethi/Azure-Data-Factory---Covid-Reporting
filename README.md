# ðŸŒ End-to-End Azure Data Engineering Pipeline for COVID-19 Analytics

## ðŸ“‘ Table of Contents
- [Overview](#overview)
- [Tools âš™](#tools-)
- [Environment Setup](#environment-setup)
- [Architecture](#architecture)
- [ðŸ“¥ Data Extraction & Ingestion](#-data-extraction--ingestion)
- [ðŸ“¦ Copy Activity](#copy-activity)
- [âš™ï¸ Data Ingestion Pipeline](#ï¸-data-ingestion-pipeline)
- [ðŸ”„ Data Transformation](#-data-transformation)
- [ðŸ”¥ Azure Databricks Activity](#-azure-databricks-activity)
- [ðŸ“¤ Copy Data to Azure SQL](#copy-data-to-azure-sql)
- [ðŸ“Š Reporting with Power BI](#-reporting-with-power-bi)

---

## ðŸ§¾ Overview
This repository showcases a comprehensive end-to-end **data engineering solution** built on **Azure**. The project integrates various Azure services to orchestrate, transform, and visualize data. Key services used:
- **Azure Data Factory (ADF)** for orchestration  
- **Azure Databricks** for transformation using PySpark  
- **Power BI** for visualization  

---

## âš™ Tools

#### ðŸ”— Data Integration/Ingestion
- ADF Data Flows within Azure Data Factory

#### ðŸ”„ Transformation
- Azure Data Factory Data Flows
- Azure Databricks (PySpark)

#### ðŸ¢ Data Warehouse Solution
- Azure SQL Database

#### ðŸ“Š Visualization
- Power BI Desktop
- Power BI Service

---

## ðŸ— Environment Setup
- Azure Subscription  
- Azure Data Factory  
- Azure Blob Storage Account  
- Azure Data Lake Storage Gen2  
- Azure SQL Database  
- Azure Databricks Cluster  

---

## ðŸ“ Architecture
![Alt Text](https://github.com/AbhishekKedarsethi/Azure-Data-Factory---Covid-Reporting/blob/bc15f8e1d8f9a572ecbfb5d9e4a5da4c3eb09955/images/Architecture.png)

---

## ðŸ“¥ Data Extraction & Ingestion

#### ðŸ“š Datasets Ingested
- **Cases and Deaths Data** â€“ Daily COVID-19 cases and fatalities across EU.
- **Hospital Admissions Data** â€“ Hospitalization and ICU admissions by date/country.
- **Population Data** â€“ Age-wise population stats for EU nations.
- **Tests Conducted Data** â€“ Historical COVID-19 testing records.

#### ðŸ”„ Ingestion Methodology
Used **Azure Data Factory** pipelines to automate extraction and ingestion:
- Sources: HTTP endpoints and Blob Storage
- Destination: Azure Data Lake Storage Gen2 (Bronze Layer)

#### âš™ï¸ ADF Activities Used
- **Validation Activity**
- **Get Metadata Activity**
- **Copy Activity**

##### ðŸ“Œ Example: Population Data Ingestion
Population dataset supports demographic analysis and mortality prediction modeling across EU.

---

## ðŸ“¦ Copy Activity
Used for reliable and performant data movement from source to Data Lake using **ADF Copy Activity**.

![Alt Text](https://github.com/AbhishekKedarsethi/Azure-Data-Factory---Covid-Reporting/blob/bc15f8e1d8f9a572ecbfb5d9e4a5da4c3eb09955/images/Copy_Activity.png)


---

## âš™ï¸ Data Ingestion Pipeline â€“ Step-by-Step

1. **Create Linked Service** to Azure Blob Storage  
2. **Create Source Dataset** (define schema & format)  
3. **Create Linked Service** to Data Lake Storage Gen2  
4. **Create Sink Dataset**  
5. **Build Pipeline** with:
   - Get Metadata Activity
   - If Condition Activity
   - Copy Activity  
6. **Load Data** into Azure Data Lake  
7. **Configure Trigger** (Daily/Hourly)

This structure was replicated across all datasets for uniform ingestion.

![Alt Text](https://github.com/AbhishekKedarsethi/Azure-Data-Factory---Covid-Reporting/blob/bc15f8e1d8f9a572ecbfb5d9e4a5da4c3eb09955/images/Copy_Pipeline.png)


---

## ðŸ”„ Data Transformation

#### Dataset: **Cases and Deaths**

1. Load from Azure Data Lake Gen2  
2. Filter for European countries  
3. Select key columns (country, date, indicator)  
4. Pivot â€˜indicatorâ€™ column to create **cases** and **deaths** columns  
5. Lookup country codes (2-digit & 3-digit)  
6. Select final columns  
7. Save to Silver Layer  
8. Schedule pipeline trigger  

---

#### Dataset: **Hospital Admissions**

##### ðŸ“† Weekly Path â€“ Admissions Per 100k

- Filter by indicators:  
  - *Weekly new hospital admissions per 100k*  
  - *Weekly new ICU admissions per 100k*  
- Join with date dimension  
- Pivot & aggregate weekly data  
- Sort by week/country  
- Save to Azure Data Lake (Silver Layer)

##### ðŸ—“ï¸ Daily Path â€“ Hospital & ICU Occupancy

- Filter indicators:  
  - *Daily hospital occupancy*  
  - *Daily ICU occupancy*  
- Pivot columns, sort data, and save final output  
- Configure scheduled trigger

---

## ðŸ”¥ Azure Databricks Activity

Used **Databricks Notebooks** within ADF to perform Spark-based scalable transformation.

#### Steps:
1. **Create Linked Service** to Databricks  
2. **Develop Notebook** with transformation logic  
3. **Create Pipeline** and add Databricks Activity  
4. **Configure error handling** with If/Else or failure paths  
5. **Automate** using scheduled or event-based triggers  

![Alt Text](https://github.com/AbhishekKedarsethi/Azure-Data-Factory---Covid-Reporting/blob/bc15f8e1d8f9a572ecbfb5d9e4a5da4c3eb09955/images/Databricks.png)


---

## ðŸ“¤ Copy Data to Azure SQL

Data from Azure Data Lake Gen2 was transferred to Azure SQL for analytics and BI reporting.

### Pipeline Steps:
1. **Linked Service** to Azure Storage (source)  
2. **Source Dataset** definition  
3. **Linked Service** to Azure SQL  
4. **Sink Dataset** configuration  
5. **Build pipeline** to load validated data  
6. **Scheduled Trigger** for automation  

![Alt Text](https://github.com/AbhishekKedarsethi/Azure-Data-Factory---Covid-Reporting/blob/bc15f8e1d8f9a572ecbfb5d9e4a5da4c3eb09955/images/SQL_pipeline.png)


---

## ðŸ“Š Reporting with Power BI

Final layer of the pipeline enables dynamic reporting on transformed datasets.

#### ðŸ“ˆ Reporting Workflow:

1. **Connect to Azure SQL Database**  
2. **Data Analysis & Aggregation**  
   - Total cases, deaths  
   - Breakdown by country and time  
3. **Create Dashboards**:
   - Daily/weekly trends  
   - Hospitalization peak periods  
   - Regional comparisons  
4. **Publish to Power BI Service**  
5. **Optional: Enable "Publish to Web"** for embedding in external platforms  

![Alt Text](https://github.com/AbhishekKedarsethi/Azure-Data-Factory---Covid-Reporting/blob/f6a57daa2d5e57dfc5b1c335040b6648f6f1543b/images/last_pic.png)


---

## ðŸ“Œ Summary
This project is a robust, production-style Azure-based **Data Engineering** workflowâ€”from raw data ingestion to final dashboardingâ€”ideal for real-world COVID-19 analytics.

---

>   
> [LinkedIn](https://in.linkedin.com/in/abishek-kedarsethi)
> ðŸ§  **Tools:** Azure Data Factory | Azure Databricks | Power BI | Azure SQL | Data Lake

---

